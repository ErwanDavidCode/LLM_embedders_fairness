# LLM Embedders Fairness Analysis

A comprehensive research project investigating fairness properties of large language model (LLM) embeddings across multiple embedding techniques and datasets. This pipeline analyzes bias and fairness metrics in embeddings generated from tabular to text-based data.

**ğŸ“„ Full Technical Report:** [Stage Report PDF](./End_of_master_intership_repport__reworked.pdf) *(Download and read for detailed methodology and findings)*

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Prerequisites & Setup](#-prerequisites--setup)
- [Project Architecture](#-project-architecture)
- [Pipeline Workflow](#-pipeline-workflow)
- [Main Script Parameters (Detailed)](#-main-script-parameters-detailed)
- [Note](#-note)

---

## ğŸ¯ Project Overview

### Research Focus

This project evaluates and compares the **fairness characteristics** of embeddings generated by **15 different embedding models** across standardized datasets (ACS data).

### Key Features

- âœ… **Multi-model comparison**: 15+ embedding models (MPNet, MiniLM, e5, UAE, etc.)
- âœ… **Flexible datasets**: Support for tabular (ACS) and text-based data
- âœ… **Scalable architecture**: Designed for 500 to 100,000+ samples
- âœ… **GPU-optimized**: SLURM-compatible for HPC clusters
- âœ… **Comprehensive pipeline**: Embeddings â†’ (Clustering) â†’ Fairness Scoring â†’ Correlations

---

## ğŸ“¦ Prerequisites & Setup

### System Requirements

This project is optimized to run on **GPU clusters** (like Compute Canada). For large datasets (>1,000 samples), **CPU-only execution is not recommended** and will be slow.

### Step 1: Clone the Repository

```bash
git clone <your-repository-url>
cd LLM_embedders_fairness/main
```

The current directory to launch the codes from is "LLM_embedders_fairness/main".

### Step 2: Download Pre-trained Models

Before running the pipeline, download all 15 embedding models:

```bash
python download_models.py
```

This will download ~15 GB of models to `../../models/` directory. You can specify your own embedders model using "SentenceTransformer".


### Step 3: Download & Process Raw Data

Generate ACS employment/income/coverage datasets:

```bash
python generate_data_ACS_folktable.py
```

This generates datasets in:
- `Data/datasets/datasets/100_00` (or another size if specified)

### Step 4: Set Up Python Environment

```bash
# Create virtual environment
python -m venv ../../venv

# Activate environment
source ../../venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Key dependencies:**
- `sentence-transformers==4.1.0`: Embedding models
- `fairlearn==0.12.0`: Fairness metrics
- `torch==2.7.1`: Deep learning (GPU-accelerated)
- `scikit-learn==1.6.1`: Clustering algorithms
- `pandas`, `numpy`, `scipy`, `matplotlib`, `seaborn`: Data processing & visualization

---

## ğŸ—ï¸ Project Architecture

### Directory Structure

```
LLM_embedders_fairness/
â”‚
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”‚
â”œâ”€â”€ Data/                               # Data directory
â”‚   â”œâ”€â”€ datasets/                       # Raw input data
â”‚   â”‚   â”œâ”€â”€ PUMS_Data_Dictionary_2018.csv
â”‚   â”‚   â”œâ”€â”€ 100_000/                    # Full dataset (100k samples)
â”‚   â”‚   â”‚   â”œâ”€â”€ ACSemployment_with_target.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ ACSincome_with_target.csv
â”‚   â”‚   â”‚   â””â”€â”€ ACSpublic_coverage_with_target.csv
â”‚   â”‚   â””â”€â”€ 500/                        # Small test dataset
â”‚   â”‚       â””â”€â”€ ACSincome_with_target.csv
â”‚   â”‚
â”‚   â””â”€â”€ embeddings/                     # Generated embeddings (output of Step 1)
â”‚       â””â”€â”€ 100_000/
â”‚           â””â”€â”€ ACSEmployment/
â”‚               â”œâ”€â”€ MPNet.csv
â”‚               â”œâ”€â”€ MiniLM-L12.csv
â”‚               â””â”€â”€ ... (one CSV per model)
â”‚
â”œâ”€â”€ models/                             # Pre-trained embedding models (to be downloaded here)
â”‚   â”œâ”€â”€ models--sentence-transformers--all-mpnet-base-v2/
â”‚   â”œâ”€â”€ models--sentence-transformers--all-MiniLM-L12-v2/
â”‚   â”œâ”€â”€ models--intfloat--e5-large-v2/
â”‚   â””â”€â”€ ... (15 models total)
â”‚
â”œâ”€â”€ embedders_fairness/main/            # Main pipeline directory
â”‚   â”‚
â”‚   â”œâ”€â”€ embedders.json                  # Model registry (paths to local models)
â”‚   â”œâ”€â”€ run_all_steps_global.sh         # â­ MAIN PIPELINE SCRIPT
â”‚   â”‚
â”‚   â”œâ”€â”€ completion_flags/               # Pipeline execution tracking
â”‚   â”‚   â”œâ”€â”€ step1_embeddings/
â”‚   â”‚   â”œâ”€â”€ step1_add_data/
â”‚   â”‚   â”œâ”€â”€ step2_clustering/
â”‚   â”‚   â””â”€â”€ step3_score/
â”‚   â”‚
â”‚   â”œâ”€â”€ run_embeddings/                 # STEP 1: Embedding generation
â”‚   â”‚   â”œâ”€â”€ run_all_embeddings.sh       # Embed tabular data manager
|   |   |â”€â”€ run_all_embeddings_text.sh  # Embed text data manager
|   |   |â”€â”€ run_single_embedding.sh     
|   |   |â”€â”€ run_single_embedding_text.sh 
â”‚   â”‚   â”œâ”€â”€ single_embedding.py         
â”‚   â”‚   â””â”€â”€ single_embedding_text.py    
â”‚   â”‚
â”‚   â”œâ”€â”€ run_add_data/                   # (Optional) Step 1b: Add additional sensitive attributes
â”‚   â”‚   â”œâ”€â”€ run_all_add_data.sh
â”‚   â”‚   â”œâ”€â”€ single_add_data_to_embeddings.py
â”‚   â”‚   â””â”€â”€ run_single_add_data.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ run_clusters/                   # STEP 2: Clustering (for unsupervised settings only)
â”‚   â”‚   â”œâ”€â”€ run_all_clustering.sh       # Cluster embeddings (k-means)
â”‚   â”‚   â”œâ”€â”€ clustering.py               
â”‚   â”‚   â””â”€â”€ run_single_clustering.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ emir/                           # STEP 3: Fairness Scoring
â”‚   â”‚   â”œâ”€â”€ emir/                       # Core scoring module
â”‚   â”‚   â”‚   â”œâ”€â”€ single_score_ISDarrin.py
â”‚   â”‚   â”‚   â”œâ”€â”€ single_score_supervised_fairentropy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ single_score_supervised_fairis.py
â”‚   â”‚   â”‚   â””â”€â”€ single_score_unsupervised_fairentropy.py
|   |   â”œâ”€â”€ run_score/                   # Bash module to run core module
â”‚   â”‚   â”‚   â”œâ”€â”€ run_all_score_ISDarrin.sh
â”‚   â”‚   |   â”œâ”€â”€ run_all_score_supervised_fairentropy.sh
â”‚   â”‚   |   â”œâ”€â”€ run_all_score_supervised_fairis.sh
â”‚   â”‚   |   â””â”€â”€ run_all_score_unsupervised_fairentropy.sh
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ... (the rest of the github of Darrin)
â”‚   â”‚
â”‚   â”œâ”€â”€ correlations/                   # STEP 4: Analysis & Visualization
â”‚   â”‚   â”œâ”€â”€ correlation_WGA_*.py        # Correlation analysis scripts
â”‚   â”‚   â”œâ”€â”€ final_plot.py               # Final visualization
â”‚   â”‚   â”œâ”€â”€ run_correlation_*.sh        # Correlation executors
â”‚   â”‚   â””â”€â”€ additional_scripts/         # Plotting helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ other_custom_embedders_in_litterature/
â”‚   â”‚   â”œâ”€â”€ AE_embedding.py             # AutoEncoder embeddings
â”‚   â”‚   â””â”€â”€ Tab_embedding.py            # Tabular embeddings
â”‚   â”‚
â”‚   â””â”€â”€ pre-pipeline_functions/
â”‚       â”œâ”€â”€ download_models.py          # Download pre-trained models
â”‚       â””â”€â”€ generate_data_ACS_folktable.py  # Generate ACS datasets
â”‚
â””â”€â”€ __results/                          # Pipeline outputs (created during execution)
    â”œâ”€â”€ pipeline_*.out / .err           # SLURM logs
    â”œâ”€â”€ seed1/K2/                       # Results organized by seed & K
    â”‚   â”œâ”€â”€ clustering/
    â”‚   â”œâ”€â”€ score/
    â”‚   â””â”€â”€ correlations/
    â””â”€â”€ seed1/KSEX_RAC1P/              # Alternative: grouping by sensitive attributes
```

### Data Flow Diagram

```
Raw Data (CSV)
    â†“
[STEP 1] run_embeddings/
    â†“ Generate embeddings with 15 models
Data/embeddings/ (15 CSV files per dataset)
    â†“
[STEP 2] run_clusters/ (optional, if K is numeric)
    â†“ K-means clustering
__results/seed{X}/K{Y}/clustering/
    â†“
[STEP 3] emir/run_score/
    â†“ Compute fairness metrics
__results/seed{X}/K{Y}/score/
    â†“
[STEP 4] correlations/
    â†“ Analysis & visualization
__results/seed{X}/K{Y}/correlations/
    â†“
final_plot.py
    â†“
Final publication-ready plots
```

---

## ğŸš€ Pipeline Workflow

The entire pipeline executes **4 sequential steps** for each combination of (seed, K) parameters:

### **STEP 1: Embedding Generation** (1-2 hours on SLURM for 100k samples)

Generates embeddings using 15 pre-trained models:

```
Input:  Raw CSV with columns: [feature1, feature2, ..., target]
Process: For each model in embedders.json:
         - Load pre-trained SentenceTransformer
         - Convert rows to text: "feature1: value1, feature2: value2, ..."
         - Generate embeddings
Output: Data/embeddings/{dataset}/{ModelName}.csv
        Each row: [embed_dim1, embed_dim2, ..., embed_dim_n, target, sensitive_features specified]
```

Warning: the orders and the sensitive features have to be specified within this script.

**Output**: 15 embedding CSV files stored in `Data/embeddings/{dataset}/`

---

### **STEP 2: Clustering** (30 mins - 1.5 hours on SLURM, only if K is numeric)

Applies K-means clustering to embeddings:

```
Input:  Embeddings from Step 1
Process: For each embedding (15 models):
         - K-means clustering with K clusters. Clustering is calculated based on all embedding columns before targeting.
Output: __results/seed{seed}/K{K}/clustering/
        Files: {ModelName}_clusters.csv
        The output file {name}_clusters.csv contains only one cluster column (one row per sample).
        Columns: [cluster_id]
```

**Skipped if:**
- K is a sensitive attribute name (e.g., "SEX_RAC1P")
- Only clustering for K numeric values (2, 4, 8, 16, 32, etc.)

---

### **STEP 3: Fairness Scoring** (30 mins - 1.5 hours on SLURM for 100k samples)

Computes fairness metrics based on embeddings and clusters/sensitive attributes:

```
Input:  Embeddings + Clustering (or sensitive attributes)
Process: For each model:
         - Compute fairness score
         - Options: supervised, unsupervised, ISDarrin
         - If supervised selected, metric depends on configuration (FAIR_ENTROPY or FAIR_IS (old))
Output: __results/seed{seed}/K{K}/score/
        Files: {ModelName}_scores.csv
```

**Scoring modes exhaustive:**
- **FAIR_ENTROPY + numeric K**: Unsupervised entropy-based fairness (Step 2 required)
- **FAIR_ENTROPY + sensitive attrs**: Supervised entropy-based fairness (no clustering)
- **FAIR_IS + sensitive attrs**: Supervised impact score with known sensitive attributes
- **ISDarrin**: Standard IS without sensitive attribute knowledge. Just the implementation fo the Darrin paper (not related to fairness).

---

### **STEP 4: Correlation Analysis** (30 min - 1 hours)

Analyzes correlations between:
- Embedding model quality (WGA)
- Correlation calculation with the score calculated in the previous step
- Generates visualizations

```
Input:  Fairness scores from Step 3
Process: - Gather and merge score calculated in previous step
         - Compute Worst Group Accuracy
         - Compute correlation
         - Plots  
Output: __results/seed{seed}/K{K}/correlations/
        Files: correlation_results.csv, plots_*.png
```

---

## âš™ï¸ Main Script Parameters (Detailed)

### **Main Loop: Seeds Ã— K Values** (Lines 47-48)

#### **Random Seeds** (`seeds`)

- **Purpose**: Run multiple experiments with different random initializations
- **Current**: `(1)` â†’ single run
- **Expand for robustness**: `(1 2 3 4 5)` â†’ 5 independent runs
- **Impact**: Multiplies total execution time by number of seeds

#### **K Values** (`K_values`) â­ **CRITICAL**

This is the **most important parameter**. Controls how fairness is grouped/measured.

**Option A: Numeric K (Unsupervised Clustering)**

```bash
K_values=(2 4 8 16)  # Will cluster into 2, 4, 8, or 16 groups
```

- **Triggers**: K-means clustering (Step 2)
- **Use when**: Sensitive attributes are unknown or for additional studies
- **Execution time**: Increases with K (more clusters = more computation)

**Option B: Sensitive Attribute Names (Supervised)**

```bash
K_values=("SEX_RAC1P")              # Group by SEX and RACE (known attributes)
K_values=("SEX")                    # Group by SEX only
K_values=("AGEP")                   # Group by AGE
K_values=("SEX_RAC1P" "SEX" "AGEP") # All three attributes
etc...
```

- **Triggers**: No clustering (Step 2 skipped)
- **Use when**: Sensitive attributes in dataset
- **Attributes in ACS data**:
  - `SEX`: Gender (Male/Female)
  - `RAC1P`: Race (White/Non-white)
  - `AGEP`: Age (Young/old)

**Option C: ISDarrin (Blind Fairness)**

```bash
K_values=("ISDarrin")  # Standard IS without attribute knowledge
```

- **Triggers**: Special ISDarrin scoring (no clustering, no sensitive attrs needed)
- **Use when**: --

**Recommended configurations:**
```bash
# Option 1: Quick test (numeric K)
K_values=(4)

# Option 2: Comprehensive unsupervised
K_values=(2 4 8 16 32)

# Option 3: Supervised (recommended for ACS data)
K_values=("SEX_RAC1P" "SEX" "AGEP")

# Option 4: Comparison
K_values=(4 "SEX" "ISDarrin")
```

---

## ğŸ“ Note

**Last updated**: December 2025
**Status**: Production-ready for HPC clusters

